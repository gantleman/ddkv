,改存储为key buf加写入计数；新加
,添加临近节点搜索；新加在原来的基础上包装接口
,数据的增改，添加（采用节点自动执行控制节点监督的模式，当节点执行失败或停止的情况下，控制节点可以重启流程）
,数据的查询查流程连续查询多个节点；
,垃圾数据的清理
,cmake的安装脚本;
,引入GRPC接口;
,引入leveldb;

在DHT内确定C与AP转换问题。
如果某个节点按各自需求确定一个C
数据写入AP的过程中是否可以确定唯一性；
这个问题可以归为写入流程。

分布式系统不稳定率，
新加入或离开的服务器之间的平均时间间隔
与每台服务器数据同步的时间比。
得出集群是否处于崩溃状态。

暂时先不考虑这个问题
cp本身就有事务方面的需求。
例如数据ＡＢ需要事务，ＢＣ需要事务，
需要使用流程的概念来保证CP的事务。

增改查和服务器加入，及同步数据的流程。

增改，控制服务器找到离目标最近的Ｃ
尝试在当前Ｃ写入数据，并获得计数器返回和临近节点。
并尝试写入临近节点，如果临近节点返回计数高于Ｃ返回计数
就失败并重新开始在Ｃ写入。
这里使用控制模式可以加快写入的速度。

查，控制服务器找到离目标最近的Ｃ
获得Ｃ的返回结果和写入计数器和临近节点。
尝试从临近节点索要数据并比较计数器。
连续获得几个计数器相同的结果表示查询结束。

服务器加入后要尝试获得临近节点，
并从左右临近节点复制数据。
针对某个ＫＥＹ要重新规范ＫＥＹ的位置。

服务器离开，定时检查临近节点是否发生了改变。
根据每个数据ＡＰ位子判断是否要同步数据。

在服务器添加或离开都会导致数据的ap排序发生变化。
假设在１前面添加一个新节点同步数据后后面的排序号是否都要改变。
如果在1后面添加一个那么前面那个是否要删除。
这样可能会导致大量数据的同步工作。
如果没有排序号那么可能导致的原因是不知道是否要同步数据。
同步多少数据。极大的可能就是重复同步数据。
因为不知道ap的末尾在哪里。

